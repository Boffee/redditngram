{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import \"bufio\"\n",
    "import \"compress/bzip2\"\n",
    "import \"encoding/json\"\n",
    "import \"errors\"\n",
    "import \"fmt\"\n",
    "import \"io\"\n",
    "import \"log\"\n",
    "import \"os\"\n",
    "import \"path\"\n",
    "import \"path/filepath\"\n",
    "import \"strings\"\n",
    "import \"time\"\n",
    "\n",
    "import \"github.com/ulikunitz/xz/lzma\"\n",
    "import \"gonum.org/v1/gonum/stat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "func timeit(f func()) {\n",
    "    const maxIter = 1e7\n",
    "    const maxDuration = time.Duration(10e9)\n",
    "    const scale = 2\n",
    "    currMaxIter := 1\n",
    "    elapsed := make([]float64, currMaxIter, maxIter)\n",
    "    var iterStart time.Time\n",
    "    start := time.Now()\n",
    "    for i := 0; ; i++ {\n",
    "        if i >= maxIter || i >= currMaxIter && time.Since(start) > maxDuration/scale {\n",
    "            break\n",
    "        }\n",
    "        if i >= currMaxIter {\n",
    "            currMaxIter *= scale\n",
    "            if currMaxIter > maxIter {\n",
    "                currMaxIter = maxIter\n",
    "            }\n",
    "            elapsed = elapsed[:currMaxIter]\n",
    "        }\n",
    "        iterStart = time.Now()\n",
    "        f()\n",
    "        elapsed[i] = time.Since(iterStart).Seconds()\n",
    "    }\n",
    "    \n",
    "    mean := time.Duration(stat.Mean(elapsed, nil) * 1e9)\n",
    "    stdDev := time.Duration(stat.StdDev(elapsed, nil) * 1e9)\n",
    "    fmt.Printf(\"%s ± %s per loop (mean ± std. dev. of %d loops)\\n\", mean, stdDev, len(elapsed))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package redditngram\n",
    "\n",
    "import (\n",
    "\t\"bufio\"\n",
    "\t\"compress/bzip2\"\n",
    "\t\"encoding/json\"\n",
    "\t\"errors\"\n",
    "\t\"fmt\"\n",
    "\t\"io\"\n",
    "\t\"log\"\n",
    "\t\"os\"\n",
    "\t\"path\"\n",
    "\t\"path/filepath\"\n",
    "\t\"time\"\n",
    "\n",
    "\t\"github.com/ulikunitz/xz/lzma\"\n",
    ")\n",
    "\n",
    "const dateFormat = \"2006-01\"\n",
    "const bz2Format = \"RC_%04d-%02d.bz2\"\n",
    "const xzFormat = \"RC_%04d-%02d.xz\"\n",
    "\n",
    "var dataStartDate, _ = time.Parse(dateFormat, \"2005-12\")\n",
    "var xzStartDate, _ = time.Parse(dateFormat, \"2017-12\")\n",
    "\n",
    "var RedditDataPath = getRedditDataPath()\n",
    "var RedditCommentsPath = path.Join(RedditDataPath, \"comments\")\n",
    "\n",
    "type Comment struct {\n",
    "\tBody        string `json:\"body\"`\n",
    "\tSubreddit   string `json:\"subreddit\"`\n",
    "\tSubredditId string `json:\"subreddit_id\"`\n",
    "\tCreatedUtc  int    `json:\"created_utc\"`\n",
    "\tScore       int    `json:\"score\"`\n",
    "\tParentId    string `json:\"parent_id\"`\n",
    "\tLinkedId    string `json:\"linked_id\"`\n",
    "}\n",
    "\n",
    "func LoadRedditCommentsJson(year, month int) (<-chan Comment, error) {\n",
    "\tdatapath, err := GetRedditCommentsLocal(year, month)\n",
    "\tif err != nil {\n",
    "\t\treturn nil, err\n",
    "\t} else if _, err := os.Stat(datapath); os.IsNotExist(err) {\n",
    "\t\treturn nil, err\n",
    "\t}\n",
    "\n",
    "\tcomments := make(chan Comment)\n",
    "\tgo func() {\n",
    "\t\tdefer close(comments)\n",
    "\t\tfh, err := os.Open(datapath)\n",
    "\t\tif err != nil {\n",
    "\t\t\tlog.Fatalln(err)\n",
    "\t\t}\n",
    "\t\tdefer fh.Close()\n",
    "\n",
    "\t\tvar reader io.Reader\n",
    "\t\tswitch filepath.Ext(datapath) {\n",
    "\t\tcase \".xz\":\n",
    "\t\t\treader, _ = lzma.NewReader(fh)\n",
    "\t\tcase \".bz2\":\n",
    "\t\t\treader = bzip2.NewReader(fh)\n",
    "\t\tdefault:\n",
    "\t\t\tlog.Panic(\"Only .xz and .bz2 are support. Given: \", datapath)\n",
    "\t\t}\n",
    "\n",
    "\t\tscanner := bufio.NewScanner(reader)\n",
    "\t\tvar comment Comment\n",
    "\t\tfor scanner.Scan() {\n",
    "\t\t\tjson.Unmarshal([]byte(scanner.Text()), &comment)\n",
    "\t\t\tif comment.Body != \"[deleted]\" {\n",
    "\t\t\t\tcomments <- comment\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}()\n",
    "\treturn comments, nil\n",
    "}\n",
    "\n",
    "func GetRedditCommentsLocal(year, month int) (datapath string, err error) {\n",
    "\tdate, _ := time.Parse(dateFormat, fmt.Sprintf(\"%04d-%02d\", year, month))\n",
    "\tif validateRedditCommentsDate(date) {\n",
    "\t\tfilename := getRedditCommentsFilename(date)\n",
    "\t\tdatapath = path.Join(RedditCommentsPath, filename)\n",
    "\t} else {\n",
    "\t\terr = errors.New(\"date out of range.\")\n",
    "\t}\n",
    "\treturn\n",
    "}\n",
    "\n",
    "func validateRedditCommentsDate(date time.Time) (is_valid bool) {\n",
    "\tdataEndDate := time.Now().AddDate(0, -1, 0)\n",
    "\tis_valid = true\n",
    "\tif date.Before(dataStartDate) || date.After(dataEndDate) {\n",
    "\t\tis_valid = false\n",
    "\t}\n",
    "\treturn\n",
    "}\n",
    "\n",
    "func getRedditCommentsFilename(date time.Time) (filename string) {\n",
    "\tformat := bz2Format\n",
    "\tif date.Before(xzStartDate) {\n",
    "\t\tformat = bz2Format\n",
    "\t}\n",
    "\tfilename = fmt.Sprintf(format, date.Year(), date.Month())\n",
    "\treturn\n",
    "}\n",
    "\n",
    "func getRedditDataPath() string {\n",
    "\tRedditDataPath := \"~/reddit\"\n",
    "\tif datapath := os.Getenv(\"REDDIT_DATA\"); datapath != \"\" {\n",
    "\t\tRedditDataPath = datapath\n",
    "\t}\n",
    "\treturn RedditDataPath\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a%5 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func CountRedditCommentsUptoNgramStrs(year, month, order int) ([]map[string]int, error) {\n",
    "    uptoNgramStrss, err := GenerateRedditCommentsUptoNgramStrs(year, month, order)\n",
    "    if err != nil {\n",
    "        return nil, err\n",
    "    }\n",
    "    uptoNgramCounts := make([]map[string]int, order)\n",
    "    for i, _ := range uptoNgramCounts {\n",
    "        uptoNgramCounts[i] = make(map[string]int)\n",
    "    }\n",
    "    lnCount := 0\n",
    "    for uptoNgramStrs := range uptoNgramStrss {\n",
    "        for i, igramStrs := range uptoNgramStrs {\n",
    "            for igramStr := range igramStrs {\n",
    "                uptoNgramCounts[i][igramStr] += 1\n",
    "            }\n",
    "        }\n",
    "        lnCount++\n",
    "        if lnCount %1000 == 0 {\n",
    "            fmt.Println(lnCount)\n",
    "        }\n",
    "    }\n",
    "    return uptoNgramCounts, nil\n",
    "}\n",
    "\n",
    "\n",
    "func GenerateRedditCommentsUptoNgramStrs(year, month, order int) (<-chan []<-chan string, error) {\n",
    "    comments, err := LoadRedditCommentsJson(year, month)\n",
    "    if err != nil {\n",
    "        return nil, err\n",
    "    }\n",
    "    \n",
    "    uptoNgramStrss := make(chan []<-chan string, order)\n",
    "    go func() {\n",
    "        for comment := range comments {\n",
    "            tokens := String2Tokens(comment.body)\n",
    "            uptoNgramStrss <- ExtractFilteredUptoNgramStrs(tokens, order, MaxRedditTokenLength)\n",
    "        }\n",
    "        close(uptoNgramStrss)\n",
    "    }()\n",
    "    return uptoNgramStrss, nil\n",
    "}\n",
    "\n",
    "\n",
    "func GenerateRedditCommentsNgramStrs(year, month, order int) (<-chan string, error) {\n",
    "    comments, err := LoadRedditCommentsJson(year, month)\n",
    "    if err != nil {\n",
    "        return nil, err\n",
    "    }\n",
    "    \n",
    "    ngramStrs := make(chan string)\n",
    "    go func() {\n",
    "        for comment := range comments {\n",
    "            tokens := String2Tokens(comment.body)\n",
    "            for ngramStr := range ExtractFilteredNgramStrs(tokens, order, MaxRedditTokenLength) {\n",
    "                ngramStrs <- ngramStr\n",
    "            }\n",
    "        }\n",
    "        close(ngramStrs)\n",
    "    }()\n",
    "    return ngramStrs, nil\n",
    "}\n",
    "\n",
    "\n",
    "func ExtractFilteredUptoNgramStrs(tokens []string, order int, maxTokLen int) []<-chan string {\n",
    "    uptoNgramStrs := make([]<-chan string, order)\n",
    "    for i := 0; i < order; i++ {\n",
    "        uptoNgramStrs[i] = ExtractFilteredNgramStrs(tokens, i + 1, maxTokLen)\n",
    "    }\n",
    "    return uptoNgramStrs\n",
    "}\n",
    "\n",
    "\n",
    "func ExtractFilteredNgramStrs(tokens []string, order int, maxTokLen int) <-chan string {\n",
    "    ngrams := ExtractNgrams(tokens, order)\n",
    "    ngramStrs := make(chan string)\n",
    "    go func() {\n",
    "        for ngram := range ngrams {\n",
    "            if !HasLongToken(ngram, maxTokLen) {\n",
    "                ngramStrs <- Tokens2String(ngram)\n",
    "            }\n",
    "        }\n",
    "        close(ngramStrs)\n",
    "    }()\n",
    "    return ngramStrs\n",
    "}\n",
    "\n",
    "\n",
    "func ExtractNgrams(tokens []string, order int) <-chan []string {\n",
    "    ngrams := make(chan []string)\n",
    "    length := len(tokens) - order + 1\n",
    "    if length < 1 {\n",
    "        close(ngrams)\n",
    "        return ngrams\n",
    "    }\n",
    "\n",
    "    go func() {\n",
    "        for i := 0; i < length; i++ {\n",
    "            ngram := tokens[i:i+order]\n",
    "            ngrams <- ngram\n",
    "        }\n",
    "        close(ngrams)\n",
    "    }()\n",
    "    return ngrams\n",
    "}\n",
    "\n",
    "func HasLongToken(tokens []string, maxTokLen int) bool {\n",
    "    for _, tok := range tokens {\n",
    "        if len(tok) > maxTokLen {\n",
    "            return true\n",
    "        }\n",
    "    }\n",
    "    return false\n",
    "}\n",
    "\n",
    "func String2Tokens(text string) []string {\n",
    "    return strings.Fields(text)\n",
    "}\n",
    "\n",
    "func Tokens2String(tokens []string) string {\n",
    "    return strings.Join(tokens, \" \")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testString := strings.Repeat(\"asdf \", 1000)\n",
    "testTokens := String2Tokens(testString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs := ExtractFilteredUptoNgramStrs(testTokens, 5, 25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch, _ := GenerateRedditCommentsNgramStrs(2005, 12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n"
     ]
    }
   ],
   "source": [
    "counts, err := CountRedditCommentsUptoNgramStrs(2006, 12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45036"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f := CreateExtractNgramStrsFunc(5, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed > time.Duration(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.556243ms"
     ]
    }
   ],
   "source": [
    "start := time.Now()\n",
    "for x := 0; x < 1000; x++ {\n",
    "    f(testString)\n",
    "}\n",
    "t := time.Now()\n",
    "elapsed := t.Sub(start)\n",
    "print(elapsed/1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
